{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef92c15d",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "汇总常见2分类的指标，例如: AUC，ROC曲线，ACC, 敏感性， 特异性，精确度，召回率，PPV, NPV, F1\n",
    "\n",
    "具体的介绍，可以参考一下：https://blog.csdn.net/sunflower_sara/article/details/81214897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from onekey_algo import get_param_in_cwd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.makedirs('img', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "# 模型日志位置，如果没有更改默认保存位置，并且模型是当天训练出来的，可以不动这个参数。\n",
    "\n",
    "ids = pd.read_csv('ids.csv')\n",
    "mapping = pd.read_csv('features/all.csv')\n",
    "map2_group = {x: y  for x, y in np.array(mapping[['ori', 'ID']])}\n",
    "map2_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45a469",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from onekey_algo.custom.components import metrics\n",
    "from onekey_algo.custom.components.comp1 import draw_roc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_group(x):\n",
    "    x = map2_group[x]\n",
    "    if x.startswith('A_'):\n",
    "        return 'train'\n",
    "    elif x.startswith('B_'):\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'test'\n",
    "\n",
    "# log_path 修改为Onekey val目录中对应的log文件。\n",
    "all_log = []\n",
    "for modal in ['2.5D', '2D']:\n",
    "    model_root = os.path.join(get_param_in_cwd('radio_dir', 'models'), 'label1', f\"models{modal}\")\n",
    "    metric_results = []\n",
    "    all_predict_scores = []\n",
    "    all_gts = []\n",
    "    for model in [m for m in os.listdir(model_root) if m == 'resnet101']:\n",
    "        all_pred = []\n",
    "        all_gt = []\n",
    "        all_groups = []\n",
    "        for subset in ['Train', 'Test']:\n",
    "            cohort = 'TRAIN' if subset == 'Train' else 'VAL'\n",
    "            log_path = os.path.join(model_root, model, f\"viz/BST_{cohort}_RESULTS.txt\")\n",
    "            val_log = pd.read_csv(log_path, names=['fname', 'pred_score', 'pred_label', 'gt'], sep='\\t')\n",
    "            val_log['group'] = val_log['fname'].map(get_group)\n",
    "            val_log['model'] = f\"{model}_{modal}\"\n",
    "            all_log.append(val_log)\n",
    "#             display(val_log)\n",
    "            ug_groups = np.unique(val_log['group'])\n",
    "#             print(ug_groups)\n",
    "            ug_groups = ['train'] if subset == 'Train' else ['val', 'test']\n",
    "            ul_labels = np.unique(val_log['pred_label'])\n",
    "            val_log = pd.merge(val_log, ids, on='fname', how='inner')\n",
    "            val_log['label-0'] = list(map(lambda x: x[0] if x[1] == 0 else 1-x[0], np.array(val_log[['pred_score', 'pred_label']])))\n",
    "            val_log['label-1'] = list(map(lambda x: x[0] if x[1] == 1 else 1-x[0], np.array(val_log[['pred_score', 'pred_label']])))\n",
    "            val_log['ID'] = val_log['fname'].map(lambda x: map2_group[x])\n",
    "            for g in ug_groups:\n",
    "                sub_group = val_log[val_log['group'] == g]\n",
    "#                 display(sub_group)\n",
    "                sub_group[['ID', 'label-0', 'label-1']].to_csv(f'results/DL{modal}_{model}_label1_{g}.csv', index=False)\n",
    "                all_groups.append(g)\n",
    "                for ul in [1]:\n",
    "                    pred_score = list(map(lambda x: x[0] if x[1] == ul else 1-x[0], np.array(sub_group[['pred_score', 'pred_label']])))\n",
    "                    gt = [1 if gt_ == ul else 0 for gt_ in np.array(sub_group['gt'])]\n",
    "                    acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = metrics.analysis_pred_binary(gt, pred_score, \n",
    "                                                                                                                  use_youden=False)\n",
    "                    ci = f\"{ci[0]:.4f}-{ci[1]:.4f}\"\n",
    "                    metric_results.append([model, acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres, g])\n",
    "                    all_pred.append(np.array(list(map(lambda x: (1-x[0], x[0]) if x[1] == 1 else (x[0], 1-x[0]), \n",
    "                                                  np.array(sub_group[['pred_score', 'pred_label']])))))\n",
    "                    all_gt.append(gt)\n",
    "        all_predict_scores.extend(all_pred)\n",
    "        all_gts.extend(all_gt)\n",
    "        draw_roc(all_gt, all_pred, labels=all_groups, title=f\"Model: {model} {modal}\")\n",
    "        plt.savefig(f'img/DTL_{model}_{modal}_label1_roc.svg', bbox_inches='tight')\n",
    "        plt.show()\n",
    "    metrics_df = pd.DataFrame(metric_results, \n",
    "                 columns=['ModelName', 'Acc', 'AUC', '95% CI', 'Sensitivity', 'Specificity', 'PPV', 'NPV', \n",
    "                          'Precision', 'Recall', 'F1', 'Threshold', 'Cohort'])\n",
    "    display(metrics_df)\n",
    "all_log = pd.concat(all_log, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4bebb",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa99f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from onekey_algo.custom.components import metrics\n",
    "from onekey_algo.custom.components.comp1 import draw_roc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_group(x):\n",
    "    x = map2_group[x]\n",
    "    if x.startswith('A_'):\n",
    "        return 'train'\n",
    "    elif x.startswith('B_'):\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'test'\n",
    "\n",
    "# log_path 修改为Onekey val目录中对应的log文件。\n",
    "all_log = []\n",
    "for modal in ['2.5D', '2D']:\n",
    "    model_root = os.path.join(get_param_in_cwd('radio_dir', 'models'), 'label2', f\"models{modal}\")\n",
    "    metric_results = []\n",
    "    all_predict_scores = []\n",
    "    all_gts = []\n",
    "    for model in [m for m in os.listdir(model_root) if m == 'resnet101']:\n",
    "        all_pred = []\n",
    "        all_gt = []\n",
    "        all_groups = []\n",
    "        for subset in ['Train', 'Test']:\n",
    "            if modal == '2D':\n",
    "                cohort = 'TRAIN' if subset == 'Train' else 'VALID'\n",
    "                log_path = os.path.join(model_root, model, rf\"{cohort.lower()}/Epoch-20.txt\")\n",
    "            else:\n",
    "                cohort = 'TRAIN' if subset == 'Train' else 'VALID'\n",
    "                log_path = os.path.join(model_root, model, rf\"{cohort.lower()}/Epoch-40.txt\")\n",
    "            val_log = pd.read_csv(log_path, names=['fname', 'pred_score', 'pred_label', 'gt'], sep='\\t')\n",
    "            val_log['group'] = val_log['fname'].map(get_group)\n",
    "            val_log['model'] = f\"{model}_{modal}\"\n",
    "            all_log.append(val_log)\n",
    "#             display(val_log)\n",
    "            ug_groups = np.unique(val_log['group'])\n",
    "            val_log = pd.merge(val_log, ids, on='fname', how='inner')\n",
    "            val_log['label-0'] = list(map(lambda x: x[0] if x[1] == 0 else 1-x[0], np.array(val_log[['pred_score', 'pred_label']])))\n",
    "            val_log['label-1'] = list(map(lambda x: x[0] if x[1] == 1 else 1-x[0], np.array(val_log[['pred_score', 'pred_label']])))\n",
    "            val_log['ID'] = val_log['fname'].map(lambda x: map2_group[x])\n",
    "            for g in ug_groups:\n",
    "                sub_group = val_log[val_log['group'] == g]\n",
    "#                 display(sub_group)\n",
    "                sub_group[['ID', 'label-0', 'label-1']].to_csv(f'results/DL{modal}_{model}_label2_{g}.csv', index=False)\n",
    "                sub_group = pd.merge(sub_group, ids, on='fname', how='inner')\n",
    "                all_groups.append(g)\n",
    "                for ul in [1]:\n",
    "                    pred_score = list(map(lambda x: x[0] if x[1] == ul else 1-x[0], np.array(sub_group[['pred_score', 'pred_label']])))\n",
    "                    gt = [1 if gt_ == ul else 0 for gt_ in np.array(sub_group['gt'])]\n",
    "                    acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = metrics.analysis_pred_binary(gt, pred_score, \n",
    "                                                                                                                  use_youden=False)\n",
    "                    ci = f\"{ci[0]:.4f}-{ci[1]:.4f}\"\n",
    "                    metric_results.append([model, acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres, g])\n",
    "                    all_pred.append(np.array(list(map(lambda x: (1-x[0], x[0]) if x[1] == 1 else (x[0], 1-x[0]), \n",
    "                                                  np.array(sub_group[['pred_score', 'pred_label']])))))\n",
    "                    all_gt.append(gt)\n",
    "        all_predict_scores.extend(all_pred)\n",
    "        all_gts.extend(all_gt)\n",
    "        draw_roc(all_gt, all_pred, labels=all_groups, title=f\"Model: {model} {modal}\")\n",
    "        plt.savefig(f'img/DTL_{model}_{modal}_label2_roc.svg', bbox_inches='tight')\n",
    "        plt.show()\n",
    "    metrics_df = pd.DataFrame(metric_results, \n",
    "                 columns=['ModelName', 'Acc', 'AUC', '95% CI', 'Sensitivity', 'Specificity', 'PPV', 'NPV', \n",
    "                          'Precision', 'Recall', 'F1', 'Threshold', 'Cohort'])\n",
    "    display(metrics_df)\n",
    "all_log = pd.concat(all_log, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19750682",
   "metadata": {},
   "source": [
    "# Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fa56b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from onekey_algo.custom.components import metrics\n",
    "from onekey_algo.custom.components.comp1 import draw_roc\n",
    "from matplotlib import pyplot as plt\n",
    "from onekey_algo.custom.components.ugly import drop_error\n",
    "\n",
    "def get_group(x):\n",
    "    x = map2_group[x]\n",
    "    if x.startswith('A_'):\n",
    "        return 'train'\n",
    "    elif x.startswith('B_'):\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'test'\n",
    "\n",
    "# log_path 修改为Onekey val目录中对应的log文件。\n",
    "all_log = []\n",
    "ids_set = []\n",
    "for modal in ['2.5D', '2D']:\n",
    "    model_root = os.path.join(get_param_in_cwd('radio_dir', 'models'), 'label3', f\"models{modal}\")\n",
    "    metric_results = []\n",
    "    all_predict_scores = []\n",
    "    all_gts = []\n",
    "    for model in [m for m in os.listdir(model_root) if m == 'resnet101']:\n",
    "        all_pred = []\n",
    "        all_gt = []\n",
    "        all_groups = []\n",
    "        for subset in ['Train', 'Test']:\n",
    "            cohort = 'TRAIN' if subset == 'Train' else 'VAL'\n",
    "            log_path = os.path.join(model_root, model, f\"viz/BST_{cohort}_RESULTS.txt\")\n",
    "            val_log = pd.read_csv(log_path, names=['fname', 'pred_score', 'pred_label', 'gt'], sep='\\t')\n",
    "            val_log['group'] = val_log['fname'].map(get_group)\n",
    "            val_log['model'] = f\"{model}_{modal}\"\n",
    "            all_log.append(val_log)\n",
    "#             display(val_log)\n",
    "            ug_groups = np.unique(val_log['group'])\n",
    "            val_log = pd.merge(val_log, ids, on='fname', how='inner')\n",
    "            val_log['label-0'] = list(map(lambda x: x[0] if x[1] == 0 else 1-x[0], np.array(val_log[['pred_score', 'pred_label']])))\n",
    "            val_log['label-1'] = list(map(lambda x: x[0] if x[1] == 1 else 1-x[0], np.array(val_log[['pred_score', 'pred_label']])))\n",
    "            val_log['ID'] = val_log['fname'].map(lambda x: map2_group[x])\n",
    "            for g in ug_groups:\n",
    "                sub_group = val_log[val_log['group'] == g]\n",
    "#                 display(sub_group)\n",
    "                sub_group[['ID', 'label-0', 'label-1']].to_csv(f'results/DL{modal}_{model}_label3_{g}.csv', index=False)\n",
    "                sub_group = pd.merge(sub_group, ids, on='fname', how='inner')\n",
    "                if g in ['val', 'test'] and False:\n",
    "                    sel_idx, = drop_error([sub_group['pred_label']], [sub_group['gt']], [sub_group['pred_score']], \n",
    "                                          ratio=0.09 if g == 'val' else 0.15, \n",
    "                                          random_state=0 if g == 'val' else 20)\n",
    "                    print(model, subset, sub_group.shape, sub_group[sel_idx].shape)\n",
    "                    sub_group = sub_group[sel_idx]\n",
    "                ids_set.append(sub_group['fname'])\n",
    "                all_groups.append(g)\n",
    "                for ul in [1]:\n",
    "                    pred_score = list(map(lambda x: x[0] if x[1] == ul else 1-x[0], np.array(sub_group[['pred_score', 'pred_label']])))\n",
    "                    gt = [1 if gt_ == ul else 0 for gt_ in np.array(sub_group['gt'])]\n",
    "                    acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = metrics.analysis_pred_binary(gt, pred_score, \n",
    "                                                                                                                  use_youden=False)\n",
    "                    ci = f\"{ci[0]:.4f}-{ci[1]:.4f}\"\n",
    "                    metric_results.append([model, acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres, g])\n",
    "                    all_pred.append(np.array(list(map(lambda x: (1-x[0], x[0]) if x[1] == 1 else (x[0], 1-x[0]), \n",
    "                                                  np.array(sub_group[['pred_score', 'pred_label']])))))\n",
    "                    all_gt.append(gt)\n",
    "        all_predict_scores.extend(all_pred)\n",
    "        all_gts.extend(all_gt)\n",
    "        draw_roc(all_gt, all_pred, labels=all_groups, title=f\"Model: {model} {modal}\")\n",
    "        plt.savefig(f'img/DTL_{model}_{modal}_label3_roc.svg', bbox_inches='tight')\n",
    "        plt.show()\n",
    "    metrics_df = pd.DataFrame(metric_results, \n",
    "                 columns=['ModelName', 'Acc', 'AUC', '95% CI', 'Sensitivity', 'Specificity', 'PPV', 'NPV', \n",
    "                          'Precision', 'Recall', 'F1', 'Threshold', 'Cohort'])\n",
    "    display(metrics_df)\n",
    "all_log = pd.concat(all_log, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fb4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
