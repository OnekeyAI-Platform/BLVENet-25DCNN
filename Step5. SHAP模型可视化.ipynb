{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain an Intermediate Layer of VGG16 on ImageNet (PyTorch)\n",
    "\n",
    "Explaining a prediction in terms of the original input image is harder than explaining the predicition in terms of a higher convolutional layer (because the higher convolutional layer is closer to the output). This notebook gives a simple example of how to use GradientExplainer to do explain a model output with respect to the 7th layer of the pretrained VGG16 network.\n",
    "\n",
    "Note that by default 200 samples are taken to compute the expectation. To run faster you can lower the number of samples per explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms, models, datasets\n",
    "import shap\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "def normalize(image):\n",
    "    if image.max() > 1:\n",
    "        image /= 255\n",
    "    image = (image - mean) / std\n",
    "    # in addition, roll the axis so that they suit pytorch\n",
    "    return torch.tensor(image.swapaxes(-1, 1).swapaxes(2, 3)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.comp2 import extract, init_from_model, init_from_onekey\n",
    "\n",
    "model, transformer, device = init_from_onekey(r'D:/20230705-ZhaoFaFa/label1/models2d/resnet101/viz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "root = r'D:/20230705-ZhaoFaFa/Data_Z_HE/crop/'\n",
    "# load the model\n",
    "model = model.eval()\n",
    "# model = models.vgg16(pretrained=True).eval()\n",
    "save_dir = r'D:/20230705-ZhaoFaFa/viz/'\n",
    "os.makedirs(save_dir, exist_ok='True')\n",
    "for sample in os.listdir(root):\n",
    "    if '+02' in sample or '-02' in sample:\n",
    "        continue\n",
    "    print(f\"正在预测：{sample}\")\n",
    "    samples = [np.expand_dims(np.array(Image.open(os.path.join(root, sample)).convert('RGB').resize((224, 224))), axis=0)]\n",
    "    samples = np.concatenate(samples, axis=0)\n",
    "    X = samples / 255\n",
    "    to_explain = X\n",
    "\n",
    "    e = shap.GradientExplainer((model, model.conv1), normalize(X))\n",
    "    shap_values, indexes = e.shap_values(normalize(to_explain), ranked_outputs=2, nsamples=50)\n",
    "\n",
    "    # get the names for the classes\n",
    "    index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "\n",
    "    # plot the explanations\n",
    "    shap_values = [np.swapaxes(np.swapaxes(s, 2, 3), 1, -1) for s in shap_values]\n",
    "\n",
    "    shap.image_plot(shap_values, to_explain, np.array([['none Increase', 'Increase']]), show=False)\n",
    "    plt.savefig(f'{save_dir}/{os.path.splitext(sample)[0]}_shap_viz.svg')\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True).eval()\n",
    "model.features[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain with local smoothing\n",
    "\n",
    "Gradient explainer uses expected gradients, which merges ideas from integrated gradients, SHAP, and SmoothGrad into a single expection equation. To use smoothing like SmoothGrad just set the local_smoothing parameter to something non-zero. This will add normally distributed noise with that standard deviation to the input during the expectation calculation. It can create smoother feature attributions that better capture correlated regions of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that because the inputs are scaled to be between 0 and 1, the local smoothing also has to be\n",
    "# scaled compared to the Keras model\n",
    "explainer = shap.GradientExplainer((model, model.conv1), normalize(X), local_smoothing=0.5)\n",
    "shap_values,indexes = explainer.shap_values(normalize(to_explain), ranked_outputs=2, nsamples=200)\n",
    "\n",
    "# get the names for the classes\n",
    "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "\n",
    "# plot the explanations\n",
    "shap_values = [np.swapaxes(np.swapaxes(s, 2, 3), 1, -1) for s in shap_values]\n",
    "\n",
    "shap.image_plot(shap_values, to_explain, np.array([['none Increase', 'Increase'], ['none Increase', 'Increase']]), plot=False)\n",
    "plt.savefig('img/shap_smoothing_viz.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
